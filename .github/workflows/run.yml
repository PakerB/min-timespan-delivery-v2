name: Run algorithm

on: push

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  build:
    name: Compile source files
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          submodules: recursive

      - name: View system info
        run: lscpu

      - name: Setup Rust
        run: curl --proto '=https' --tlsv1.2 https://sh.rustup.rs -sSf | sh -s -- --default-toolchain=1.89 -y

      - name: Compile source files
        run: cargo build --release

      - name: Display help menu
        run: target/release/min-timespan-delivery run --help

      - name: Upload executable
        uses: actions/upload-artifact@v4
        with:
          name: executable
          path: target/release/min-timespan-delivery

  solve:
    name: Run algorithm
    runs-on: ubuntu-latest
    needs: build
    strategy:
      fail-fast: false
      matrix:
        steps: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          submodules: recursive

      - name: Download executable
        uses: actions/download-artifact@v4
        with:
          name: executable
          path: .

      - name: Update permission
        run: chmod +x min-timespan-delivery

      - name: Run algorithm
        run: |
          exitcode=0
          set +e

          execute() {
            command=$1
            echo "Running \"$command\""
            $command

            status=$?
            if [ $status -ne 0 ]
            then
              echo "::error::\"$command\" exit with status $status"
              exitcode=1
            fi
          }

          # Collect all files and sort them
          echo "Collecting files..."
          all_files=($(find problems/data/* -type f -name "*.txt" | sort))
          total_files=${#all_files[@]}
          
          echo "Total files found: $total_files"
          
          # Calculate which files THIS job should process
          total_jobs=10
          job_index=${{ matrix.steps }}
          files_per_job=$(( (total_files + total_jobs - 1) / total_jobs ))
          
          start_index=$(( job_index * files_per_job ))
          end_index=$(( start_index + files_per_job ))
          
          # Ensure we don't exceed array bounds
          if [ $end_index -gt $total_files ]; then
            end_index=$total_files
          fi
          
          echo "================================"
          echo "Job $job_index: Processing files $start_index to $((end_index - 1))"
          echo "This job will process $((end_index - start_index)) files"
          echo "================================"
          
          processed=0
          for i in $(seq $start_index $((end_index - 1)))
          do
            path=${all_files[$i]}
            
            # Check if file exists and has customers field
            if [ -f "$path" ] && grep -q "customers" "$path"; then
              customers=$(grep -oP "(?<=customers )\d+" "$path" 2>/dev/null || echo "0")
              
              # Only process files with <= 200 customers
              if [ "$customers" -le 200 ] && [ "$customers" -gt 0 ]; then
                echo "[$((processed + 1))/$((end_index - start_index))] Processing: $(basename $path) (customers: $customers)"
                execute "./min-timespan-delivery run $path --disable-logging --extra ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                ((processed++))
              else
                echo "Skipping $(basename $path) (customers: $customers)"
              fi
            fi
          done

          echo "================================"
          echo "Job $job_index completed: Processed $processed files"
          echo "================================"
          exit $exitcode

      - name: Upload results
        uses: actions/upload-artifact@v4
        if: ${{ always() }}
        with:
          name: output-${{ matrix.steps }}
          path: outputs/*

  summary:
    name: Summarize results
    runs-on: ubuntu-latest
    if: ${{ always() }}
    needs: solve

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Download results
        uses: actions/download-artifact@v4
        with:
          path: outputs/
          pattern: output-*
          merge-multiple: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Summarize results
        run: |
          python scripts/summary.py
          
          # Also create individual summary files for each batch (for large datasets)
          output_count=$(find outputs -name "*.json" -type f 2>/dev/null | wc -l)
          echo "Total output files: $output_count"
          
          if [ $output_count -gt 1000 ]; then
            echo "Large dataset detected, creating batched summaries..."
            python scripts/summary.py --batch-mode
          fi
        env:
          PYTHONRECURSIONLIMIT: 10000

      - name: Upload summary files
        uses: actions/upload-artifact@v4
        if: ${{ always() }}
        with:
          name: summary-csv
          path: |
            outputs/summary.csv
            outputs/summary.db

      - name: Upload everything
        uses: actions/upload-artifact@v4
        if: ${{ always() }}
        with:
          name: summary
          path: outputs/*
